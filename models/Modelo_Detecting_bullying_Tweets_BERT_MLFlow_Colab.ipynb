{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OAGkZYJ-rW0N",
        "outputId": "3d5333c0-4b6b-4b71-aca6-ed9add892239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.1\n",
            "0.14.0\n"
          ]
        }
      ],
      "source": [
        "import sklearn, imblearn\n",
        "print(sklearn.__version__)\n",
        "print(imblearn.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inV3yMIE4Ze",
        "outputId": "6171ed2e-5fe9-4abb-c37b-b1d9ec98f1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)\n",
            "Using Colab cache for faster access to the 'cyberbullying-classification' dataset.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "!pip install kagglehub\n",
        "import kagglehub\n",
        "andrewmvd_cyberbullying_classification_path = kagglehub.dataset_download('andrewmvd/cyberbullying-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTSkJpBwriyX",
        "outputId": "b0afbcab-db78-46d9-8518-9aa75d16f4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/cyberbullying-classification\n"
          ]
        }
      ],
      "source": [
        "print(andrewmvd_cyberbullying_classification_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiIg_5F_5Qr9"
      },
      "source": [
        "# Detecting bullying Tweets with BERT Transformer Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiabNLkT5QsB"
      },
      "source": [
        "Este proyecto trata sobre el an√°lisis de tweets relacionados con el ciberacoso, con el objetivo de realizar un An√°lisis de Sentimientos utilizando BERT en PyTorch para predecir si un tweet est√° relacionado con ciberacoso o no.\n",
        "En particular, los tweets de acoso se dividen en 4 categor√≠as: religi√≥n, edad, raza y g√©nero.\n",
        "\n",
        "El proyecto est√° dividido en las siguientes secciones:\n",
        "\n",
        "Importaci√≥n de datos\n",
        "\n",
        "Limpieza de texto con funciones definidas por el usuario\n",
        "\n",
        "Clasificador base Naive Bayes\n",
        "\n",
        "Preparaci√≥n de datos para BERT: Tokenizaci√≥n\n",
        "\n",
        "Clasificador BERT en PyTorch\n",
        "\n",
        "Resumen de resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bRgtas5QsC"
      },
      "source": [
        "# Resumen de resultados principales:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-23T16:13:11.831681Z",
          "iopub.status.busy": "2022-01-23T16:13:11.831378Z",
          "iopub.status.idle": "2022-01-23T16:13:11.837312Z",
          "shell.execute_reply": "2022-01-23T16:13:11.83616Z",
          "shell.execute_reply.started": "2022-01-23T16:13:11.831647Z"
        },
        "id": "zCr49gEqE4Zj"
      },
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        " ![image.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCxT_DktE4Zk"
      },
      "source": [
        "El clasificador base *Naive Bayes* tuvo un desempe√±o bastante bueno en el conjunto de datos, con una **precisi√≥n general del 85%** entre todas las clases. sin embargo vemos que el score F1 no es bueno y en la clase que predice que no son de \"bullying\" tiene un recall de 0.46, es decir que el 46 por ciento de las veces se confune, aunque no es problem√°tico. Lo problem√°tico es 0.85 de recall de gender, es decir que hay un 15% de casos de bullying de genero que no se detectar√≠an.\n",
        "\n",
        "*BERT* obtuvo el mejor rendimiento, con una precisi√≥n general alrededor del 95% y puntuaciones F1 superiores al 96%.\n",
        "En general, los algoritmos pudieron distinguir correctamente los diferentes temas de los tweets de acoso, y tuvieron m√°s dificultades con la clase menos poblada \"no ciberacoso\" y la clase \"g√©nero\" (logrando menor precisi√≥n y recall en comparaci√≥n con otras clases).\n",
        "Por esta raz√≥n, podr√≠a ser una buena idea recopilar m√°s datos de estas clases y as√≠ intentar lograr **una mayor precisi√≥n y puntuaci√≥n F1.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-06-02T01:54:45.149191Z",
          "iopub.status.busy": "2023-06-02T01:54:45.148845Z",
          "iopub.status.idle": "2023-06-02T01:54:45.178621Z",
          "shell.execute_reply": "2023-06-02T01:54:45.177806Z",
          "shell.execute_reply.started": "2023-06-02T01:54:45.149127Z"
        },
        "id": "pChhxDsk5QsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da4462e-c1a2-4d99-cbf2-82c467675073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/cyberbullying-classification/cyberbullying_tweets.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy5y7LobE4Zm"
      },
      "source": [
        "## Custom functions definition:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-02T01:54:45.185395Z",
          "iopub.status.busy": "2023-06-02T01:54:45.184756Z",
          "iopub.status.idle": "2023-06-02T01:54:45.19344Z",
          "shell.execute_reply": "2023-06-02T01:54:45.1926Z",
          "shell.execute_reply.started": "2023-06-02T01:54:45.185352Z"
        },
        "id": "Lf3xiz4cE4Zn"
      },
      "outputs": [],
      "source": [
        "def conf_matrix(y, y_pred, title, labels):\n",
        "    fig, ax =plt.subplots(figsize=(7.5,7.5))\n",
        "    ax=sns.heatmap(confusion_matrix(y, y_pred), annot=True, cmap=\"Purples\", fmt='g', cbar=False, annot_kws={\"size\":30})\n",
        "    plt.title(title, fontsize=25)\n",
        "    ax.xaxis.set_ticklabels(labels, fontsize=16)\n",
        "    ax.yaxis.set_ticklabels(labels, fontsize=14.5)\n",
        "    ax.set_ylabel('Test', fontsize=25)\n",
        "    ax.set_xlabel('Predicted', fontsize=25)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-02T01:54:45.196911Z",
          "iopub.status.busy": "2023-06-02T01:54:45.196376Z",
          "iopub.status.idle": "2023-06-02T01:54:54.147482Z",
          "shell.execute_reply": "2023-06-02T01:54:54.146535Z",
          "shell.execute_reply.started": "2023-06-02T01:54:45.196864Z"
        },
        "id": "6naMfWApE4Zo",
        "outputId": "133ce1a5-8cd0-44c6-d676-02db46619023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-02T01:54:54.15142Z",
          "iopub.status.busy": "2023-06-02T01:54:54.15116Z",
          "iopub.status.idle": "2023-06-02T01:55:03.26546Z",
          "shell.execute_reply": "2023-06-02T01:55:03.264506Z",
          "shell.execute_reply.started": "2023-06-02T01:54:54.151388Z"
        },
        "id": "gemMAQTSE4Zo",
        "outputId": "d034b2c9-21ca-474b-9641-8291063ad345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.12/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.12/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install contractions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl7zPPdtE4Zo"
      },
      "source": [
        "## Importar librarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Db95M-ByrNd"
      },
      "outputs": [],
      "source": [
        "!pip install emoji\n",
        "!pip install gensim\n",
        "!pip install seaborn\n",
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu2mOJ9ZrW0a"
      },
      "outputs": [],
      "source": [
        "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Ô∏è‚É£ Montar Google Drive (para guardar los runs)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Carpeta donde se guardar√°n los experiments\n",
        "mlruns_path = \"/content/drive/MyDrive/mlruns\"\n",
        "\n",
        "# 2Ô∏è‚É£ Instalar pyngrok si no est√°\n",
        "!pip install -q pyngrok mlflow\n",
        "\n",
        "!ngrok authtoken 32NmcUxGo1PtZFZy1XaKM9nNig2_6NDVrZiPTZjmf6Ckpnf1S\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# 3Ô∏è‚É£ Cerrar t√∫neles y procesos previos (para evitar conflictos)\n",
        "ngrok.kill()\n",
        "!pkill -f \"mlflow ui\"\n",
        "\n",
        "# 4Ô∏è‚É£ Lanzar MLflow UI en background\n",
        "get_ipython().system_raw(f\"mlflow ui --backend-store-uri {mlruns_path} --port 5000 --host 0.0.0.0 &\")\n",
        "\n",
        "# 5Ô∏è‚É£ Abrir un t√∫nel ngrok al puerto 5000\n",
        "mlflow_url = ngrok.connect(5000)\n",
        "print(\"üëâ MLflow UI est√° disponible aqu√≠:\", mlflow_url)\n"
      ],
      "metadata": {
        "id": "qk3d3f2nUfjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:03.267566Z",
          "iopub.status.busy": "2023-06-02T01:55:03.267318Z",
          "iopub.status.idle": "2023-06-02T01:55:06.717286Z",
          "shell.execute_reply": "2023-06-02T01:55:06.716524Z",
          "shell.execute_reply.started": "2023-06-02T01:55:03.267533Z"
        },
        "id": "D0GOzHmK5QsH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Libraries for general purpose\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Text cleaning\n",
        "import re\n",
        "import string\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Descargar si a√∫n no lo hiciste\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# Data preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from langdetect import detect, LangDetectException\n",
        "import contractions\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Naive Bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# PyTorch LSTM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Tokenization for LSTM\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Transformers library for BERT\n",
        "import transformers\n",
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import time\n",
        "\n",
        "# Set seed for reproducibility\n",
        "import random\n",
        "seed_value = 2042\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.despine()\n",
        "\n",
        "#plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n",
        "\n",
        "# Define stop words for text cleaning\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Initialize lemmatizer for text cleaning\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#Mlflow\n",
        "import mlflow\n",
        "import mlflow.sklearn  # o mlflow.tensorflow / mlflow.pytorch seg√∫n tu framework\n",
        "\n",
        "# Opcional: configurar la URI de tracking (por defecto se guarda en ./mlruns)\n",
        "#mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "\n",
        "# Opcional: asignar un nombre al experimento\n",
        "mlflow.set_experiment(\"mi_experimento_Naive_Bayes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv7P6PMorW0c"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "print(sklearn.__version__)   # deber√≠a ser 1.3.2\n",
        "print(imblearn.__version__)  # deber√≠a ser 0.12.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp9PbBAxE4Zq"
      },
      "source": [
        "## Data Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:06.71926Z",
          "iopub.status.busy": "2023-06-02T01:55:06.718963Z",
          "iopub.status.idle": "2023-06-02T01:55:06.835451Z",
          "shell.execute_reply": "2023-06-02T01:55:06.834613Z",
          "shell.execute_reply.started": "2023-06-02T01:55:06.719219Z"
        },
        "id": "aCVJ1XJi5QsI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/kaggle/input/cyberbullying-classification/cyberbullying_tweets.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:06.83913Z",
          "iopub.status.busy": "2023-06-02T01:55:06.838891Z",
          "iopub.status.idle": "2023-06-02T01:55:06.852652Z",
          "shell.execute_reply": "2023-06-02T01:55:06.851746Z",
          "shell.execute_reply.started": "2023-06-02T01:55:06.8391Z"
        },
        "id": "NPhe4rM35QsJ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:06.854815Z",
          "iopub.status.busy": "2023-06-02T01:55:06.854309Z",
          "iopub.status.idle": "2023-06-02T01:55:06.878423Z",
          "shell.execute_reply": "2023-06-02T01:55:06.877515Z",
          "shell.execute_reply.started": "2023-06-02T01:55:06.85477Z"
        },
        "id": "EfuNMKB8E4Zq"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdboO_9SE4Zr"
      },
      "source": [
        "First we rename the columns using shorter words for easier reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:06.880184Z",
          "iopub.status.busy": "2023-06-02T01:55:06.87982Z",
          "iopub.status.idle": "2023-06-02T01:55:06.887777Z",
          "shell.execute_reply": "2023-06-02T01:55:06.886991Z",
          "shell.execute_reply.started": "2023-06-02T01:55:06.88013Z"
        },
        "id": "AwUN352x5QsK"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns={'tweet_text': 'text', 'cyberbullying_type': 'sentiment'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9wTHjTcc1D7"
      },
      "source": [
        "### Tweets duplicados?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:06.889655Z",
          "iopub.status.busy": "2023-06-02T01:55:06.889344Z",
          "iopub.status.idle": "2023-06-02T01:55:06.938405Z",
          "shell.execute_reply": "2023-06-02T01:55:06.93757Z",
          "shell.execute_reply.started": "2023-06-02T01:55:06.889617Z"
        },
        "id": "uK85wAdTE4Zr"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx-xUe5iE4Zr"
      },
      "source": [
        "There are some duplicated tweets, we will remove them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:06.94008Z",
          "iopub.status.busy": "2023-06-02T01:55:06.939706Z",
          "iopub.status.idle": "2023-06-02T01:55:06.979559Z",
          "shell.execute_reply": "2023-06-02T01:55:06.978738Z",
          "shell.execute_reply.started": "2023-06-02T01:55:06.940038Z"
        },
        "id": "4u7mn7wkchxj"
      },
      "outputs": [],
      "source": [
        "df = df[~df.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:06.981405Z",
          "iopub.status.busy": "2023-06-02T01:55:06.98111Z",
          "iopub.status.idle": "2023-06-02T01:55:07.005087Z",
          "shell.execute_reply": "2023-06-02T01:55:07.00434Z",
          "shell.execute_reply.started": "2023-06-02T01:55:06.981362Z"
        },
        "id": "oedUGlQ9crg2"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srlyrBn7E4Zs"
      },
      "source": [
        "### Classes desbalanceadas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:07.009944Z",
          "iopub.status.busy": "2023-06-02T01:55:07.0097Z",
          "iopub.status.idle": "2023-06-02T01:55:07.024715Z",
          "shell.execute_reply": "2023-06-02T01:55:07.023741Z",
          "shell.execute_reply.started": "2023-06-02T01:55:07.009912Z"
        },
        "id": "c82luV2N5QsN"
      },
      "outputs": [],
      "source": [
        "df.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSs8T2kSE4Zs"
      },
      "source": [
        "The classes look balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-19T09:34:52.112295Z",
          "iopub.status.busy": "2022-01-19T09:34:52.112005Z",
          "iopub.status.idle": "2022-01-19T09:34:53.14386Z",
          "shell.execute_reply": "2022-01-19T09:34:53.142913Z",
          "shell.execute_reply.started": "2022-01-19T09:34:52.112262Z"
        },
        "id": "DGmYrF4d5QsP"
      },
      "source": [
        "# Limpieza de los Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVPNERqPE4Zs"
      },
      "source": [
        "Next, we will define custom functions to clean the texts of the tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:07.027276Z",
          "iopub.status.busy": "2023-06-02T01:55:07.026969Z",
          "iopub.status.idle": "2023-06-02T01:55:07.050047Z",
          "shell.execute_reply": "2023-06-02T01:55:07.049136Z",
          "shell.execute_reply.started": "2023-06-02T01:55:07.027237Z"
        },
        "id": "E5E1UwMc5QsQ"
      },
      "outputs": [],
      "source": [
        "# Clean emojis from text\n",
        "def strip_emoji(text):\n",
        "    return emoji.replace_emoji(text, replace=\"\")\n",
        "\n",
        "# Remove punctuations, stopwords, links, mentions and new line characters\n",
        "def strip_all_entities(text):\n",
        "    text = re.sub(r'\\r|\\n', ' ', text.lower())  # Replace newline and carriage return with space, and convert to lowercase\n",
        "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)  # Remove links and mentions\n",
        "    text = re.sub(r'[^\\x00-\\x7f]', '', text)  # Remove non-ASCII characters\n",
        "    banned_list = string.punctuation\n",
        "    table = str.maketrans('', '', banned_list)\n",
        "    text = text.translate(table)\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "# Clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
        "def clean_hashtags(tweet):\n",
        "    # Remove hashtags at the end of the sentence\n",
        "    new_tweet = re.sub(r'(\\s+#[\\w-]+)+\\s*$', '', tweet).strip()\n",
        "\n",
        "    # Remove the # symbol from hashtags in the middle of the sentence\n",
        "    new_tweet = re.sub(r'#([\\w-]+)', r'\\1', new_tweet).strip()\n",
        "\n",
        "    return new_tweet\n",
        "\n",
        "# Filter special characters such as & and $ present in some words\n",
        "def filter_chars(text):\n",
        "    return ' '.join('' if ('$' in word) or ('&' in word) else word for word in text.split())\n",
        "\n",
        "# Remove multiple spaces\n",
        "def remove_mult_spaces(text):\n",
        "    return re.sub(r\"\\s\\s+\", \" \", text)\n",
        "\n",
        "# Function to check if the text is in English, and return an empty string if it's not\n",
        "def filter_non_english(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "    except LangDetectException:\n",
        "        lang = \"unknown\"\n",
        "    return text if lang == \"en\" else \"\"\n",
        "\n",
        "# Expand contractions\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "# Remove numbers\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Lemmatize words\n",
        "def lemmatize(text):\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Remove short words\n",
        "def remove_short_words(text, min_len=2):\n",
        "    words = text.split()\n",
        "    long_words = [word for word in words if len(word) >= min_len]\n",
        "    return ' '.join(long_words)\n",
        "\n",
        "# Replace elongated words with their base form\n",
        "def replace_elongated_words(text):\n",
        "    regex_pattern = r'\\b(\\w+)((\\w)\\3{2,})(\\w*)\\b'\n",
        "    return re.sub(regex_pattern, r'\\1\\3\\4', text)\n",
        "\n",
        "# Remove repeated punctuation\n",
        "def remove_repeated_punctuation(text):\n",
        "    return re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
        "\n",
        "# Remove extra whitespace\n",
        "def remove_extra_whitespace(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def remove_url_shorteners(text):\n",
        "    return re.sub(r'(?:http[s]?://)?(?:www\\.)?(?:bit\\.ly|goo\\.gl|t\\.co|tinyurl\\.com|tr\\.im|is\\.gd|cli\\.gs|u\\.nu|url\\.ie|tiny\\.cc|alturl\\.com|ow\\.ly|bit\\.do|adoro\\.to)\\S+', '', text)\n",
        "\n",
        "# Remove spaces at the beginning and end of the tweet\n",
        "def remove_spaces_tweets(tweet):\n",
        "    return tweet.strip()\n",
        "\n",
        "# Remove short tweets\n",
        "def remove_short_tweets(tweet, min_words=3):\n",
        "    words = tweet.split()\n",
        "    return tweet if len(words) >= min_words else \"\"\n",
        "\n",
        "# Function to call all the cleaning functions in the correct order\n",
        "def clean_tweet(tweet):\n",
        "    tweet = strip_emoji(tweet)\n",
        "    tweet = expand_contractions(tweet)\n",
        "    tweet = filter_non_english(tweet)\n",
        "    tweet = strip_all_entities(tweet)\n",
        "    tweet = clean_hashtags(tweet)\n",
        "    tweet = filter_chars(tweet)\n",
        "    tweet = remove_mult_spaces(tweet)\n",
        "    tweet = remove_numbers(tweet)\n",
        "    tweet = lemmatize(tweet)\n",
        "    tweet = remove_short_words(tweet)\n",
        "    tweet = replace_elongated_words(tweet)\n",
        "    tweet = remove_repeated_punctuation(tweet)\n",
        "    tweet = remove_extra_whitespace(tweet)\n",
        "    tweet = remove_url_shorteners(tweet)\n",
        "    tweet = remove_spaces_tweets(tweet)\n",
        "    tweet = remove_short_tweets(tweet)\n",
        "    tweet = ' '.join(tweet.split())  # Remove multiple spaces between words\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T01:55:07.051999Z",
          "iopub.status.busy": "2023-06-02T01:55:07.051363Z",
          "iopub.status.idle": "2023-06-02T02:03:23.943346Z",
          "shell.execute_reply": "2023-06-02T02:03:23.942525Z",
          "shell.execute_reply.started": "2023-06-02T01:55:07.051957Z"
        },
        "id": "g25EfeWmE4Zt"
      },
      "outputs": [],
      "source": [
        "df['text_clean'] = [clean_tweet(tweet) for tweet in df['text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:23.945239Z",
          "iopub.status.busy": "2023-06-02T02:03:23.944862Z",
          "iopub.status.idle": "2023-06-02T02:03:23.956483Z",
          "shell.execute_reply": "2023-06-02T02:03:23.955607Z",
          "shell.execute_reply.started": "2023-06-02T02:03:23.945183Z"
        },
        "id": "gnYujHRKE4Zu"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZnVbI7sE4Zu"
      },
      "source": [
        "### Are there duplicate tweets after the cleaning?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:23.958348Z",
          "iopub.status.busy": "2023-06-02T02:03:23.95807Z",
          "iopub.status.idle": "2023-06-02T02:03:23.976094Z",
          "shell.execute_reply": "2023-06-02T02:03:23.975338Z",
          "shell.execute_reply.started": "2023-06-02T02:03:23.958311Z"
        },
        "id": "1z9U__jPE4Zu"
      },
      "outputs": [],
      "source": [
        "print(f'There are around {int(df[\"text_clean\"].duplicated().sum())} duplicated tweets, we will remove them.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:23.978088Z",
          "iopub.status.busy": "2023-06-02T02:03:23.977743Z",
          "iopub.status.idle": "2023-06-02T02:03:24.007089Z",
          "shell.execute_reply": "2023-06-02T02:03:24.006308Z",
          "shell.execute_reply.started": "2023-06-02T02:03:23.978047Z"
        },
        "id": "OtTa6vW4E4Zu"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(\"text_clean\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Tbyr_J2E4Zu"
      },
      "source": [
        "We removed the duplicated cleaned tweets. How is the class balance after the cleaning?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:24.008795Z",
          "iopub.status.busy": "2023-06-02T02:03:24.008492Z",
          "iopub.status.idle": "2023-06-02T02:03:24.020196Z",
          "shell.execute_reply": "2023-06-02T02:03:24.019209Z",
          "shell.execute_reply.started": "2023-06-02T02:03:24.008751Z"
        },
        "id": "WcUKZqIOE4Zu"
      },
      "outputs": [],
      "source": [
        "df.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0AqpQkME4Zu"
      },
      "source": [
        "**Se elimina la clase \"other cyberbullying\"**\n",
        "\n",
        "We can see that lots of tweets of the class \"other_cyberbullying\" have been removed. Since the class is very unbalanced compared to the other classes and looks too \"generic\", we decide to remove the tweets labeled belonging to this class.<br>\n",
        "EDIT: by performing some tests, the f1 score for predicting the \"other_cyberbullying\" resulted to be around 60%, a value far lower compared to the othter f1 scores (around 95% using LSTM model). This supports the decision of removing this generic class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:24.022039Z",
          "iopub.status.busy": "2023-06-02T02:03:24.021691Z",
          "iopub.status.idle": "2023-06-02T02:03:24.037187Z",
          "shell.execute_reply": "2023-06-02T02:03:24.036422Z",
          "shell.execute_reply.started": "2023-06-02T02:03:24.021997Z"
        },
        "id": "AD1HPdoqE4Zz"
      },
      "outputs": [],
      "source": [
        "df = df[df[\"sentiment\"]!=\"other_cyberbullying\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la8MpiawE4Zz"
      },
      "source": [
        "Then we also define a list of the classes names, which will be useful for the future plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:24.039132Z",
          "iopub.status.busy": "2023-06-02T02:03:24.038366Z",
          "iopub.status.idle": "2023-06-02T02:03:24.044996Z",
          "shell.execute_reply": "2023-06-02T02:03:24.044134Z",
          "shell.execute_reply.started": "2023-06-02T02:03:24.039092Z"
        },
        "id": "_mdcuRbYE4Z0"
      },
      "outputs": [],
      "source": [
        "sentiments = [\"religion\",\"age\",\"ethnicity\",\"gender\",\"not bullying\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osCIfvQ9E4Z0"
      },
      "source": [
        "# An√°lisis de longitud de Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Lzp6ZmE4Z0"
      },
      "source": [
        "Now we will define a new dataframe column containing the length of the cleaned tweets in terms of number of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:24.046896Z",
          "iopub.status.busy": "2023-06-02T02:03:24.046599Z",
          "iopub.status.idle": "2023-06-02T02:03:24.106733Z",
          "shell.execute_reply": "2023-06-02T02:03:24.105946Z",
          "shell.execute_reply.started": "2023-06-02T02:03:24.046857Z"
        },
        "id": "vQsHVXTA5QsV"
      },
      "outputs": [],
      "source": [
        "df['text_len'] = [len(text.split()) for text in df.text_clean]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:24.109947Z",
          "iopub.status.busy": "2023-06-02T02:03:24.109739Z",
          "iopub.status.idle": "2023-06-02T02:03:24.451036Z",
          "shell.execute_reply": "2023-06-02T02:03:24.450262Z",
          "shell.execute_reply.started": "2023-06-02T02:03:24.109919Z"
        },
        "id": "HZcu8uGh5QsW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n",
        "plt.title('Count of tweets with less than 10 words', fontsize=20)\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmN9566u5QsX"
      },
      "source": [
        "### What about long tweets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:24.453325Z",
          "iopub.status.busy": "2023-06-02T02:03:24.452453Z",
          "iopub.status.idle": "2023-06-02T02:03:24.486382Z",
          "shell.execute_reply": "2023-06-02T02:03:24.485591Z",
          "shell.execute_reply.started": "2023-06-02T02:03:24.453279Z"
        },
        "id": "2Dv2aZRv5QsY"
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=['text_len'], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:24.487823Z",
          "iopub.status.busy": "2023-06-02T02:03:24.487533Z",
          "iopub.status.idle": "2023-06-02T02:03:25.449266Z",
          "shell.execute_reply": "2023-06-02T02:03:25.448515Z",
          "shell.execute_reply.started": "2023-06-02T02:03:24.487779Z"
        },
        "id": "Zt9YFv935QsY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "ax = sns.countplot(x='text_len', data=df[(df['text_len']<=1000) & (df['text_len']>10)], palette='Blues_r')\n",
        "plt.title('Count of tweets with high number of words', fontsize=25)\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzY9dDnF5QsY"
      },
      "source": [
        "We also will remove tweets that are too long (with more than 100 words)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.451257Z",
          "iopub.status.busy": "2023-06-02T02:03:25.450767Z",
          "iopub.status.idle": "2023-06-02T02:03:25.462174Z",
          "shell.execute_reply": "2023-06-02T02:03:25.461429Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.451215Z"
        },
        "id": "teb7a02F5QsY"
      },
      "outputs": [],
      "source": [
        "df = df[df['text_len'] < df['text_len'].quantile(0.995)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIQzoGiE4Z1"
      },
      "source": [
        "Then we also get the length of the longest tweet since it will be useful later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.464173Z",
          "iopub.status.busy": "2023-06-02T02:03:25.463808Z",
          "iopub.status.idle": "2023-06-02T02:03:25.471732Z",
          "shell.execute_reply": "2023-06-02T02:03:25.470728Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.464134Z"
        },
        "id": "HyQak-0QI9Mk"
      },
      "outputs": [],
      "source": [
        "max_len = np.max(df['text_len'])\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.473594Z",
          "iopub.status.busy": "2023-06-02T02:03:25.473243Z",
          "iopub.status.idle": "2023-06-02T02:03:25.493626Z",
          "shell.execute_reply": "2023-06-02T02:03:25.492834Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.473539Z"
        },
        "id": "NZD-8GJd5Qsa"
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=[\"text_len\"], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yV3tqlCE4Z2"
      },
      "source": [
        "## Sentiment column encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ9lUNrnE4Z2"
      },
      "source": [
        "The target column will be encoded by ordinal encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.495386Z",
          "iopub.status.busy": "2023-06-02T02:03:25.495104Z",
          "iopub.status.idle": "2023-06-02T02:03:25.526715Z",
          "shell.execute_reply": "2023-06-02T02:03:25.525925Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.495347Z"
        },
        "id": "NIS_nyXBG416"
      },
      "outputs": [],
      "source": [
        "df['sentiment'] = df['sentiment'].replace({'religion':0,'age':1,'ethnicity':2,'gender':3,'not_cyberbullying':4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiG-rqpIzKGi"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELMGaiE-F7yn"
      },
      "source": [
        "## Train - Test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrLwRbummpEq"
      },
      "source": [
        "Now we need to split the dataset into a train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.528482Z",
          "iopub.status.busy": "2023-06-02T02:03:25.528179Z",
          "iopub.status.idle": "2023-06-02T02:03:25.532944Z",
          "shell.execute_reply": "2023-06-02T02:03:25.532221Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.528442Z"
        },
        "id": "BF01CgBtBONZ"
      },
      "outputs": [],
      "source": [
        "X = df['text_clean']\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.534808Z",
          "iopub.status.busy": "2023-06-02T02:03:25.534082Z",
          "iopub.status.idle": "2023-06-02T02:03:25.567159Z",
          "shell.execute_reply": "2023-06-02T02:03:25.566498Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.534766Z"
        },
        "id": "fvQexohPGAZf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0d0lSX0GbNS"
      },
      "source": [
        "## Train - Validation split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OsrkfnCmtk0"
      },
      "source": [
        "Moreover, we will further split the training set to extract a validation set, which will be used to monior the accuracy and loss to avoid overfitting during the model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.568755Z",
          "iopub.status.busy": "2023-06-02T02:03:25.568474Z",
          "iopub.status.idle": "2023-06-02T02:03:25.594169Z",
          "shell.execute_reply": "2023-06-02T02:03:25.593523Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.568718Z"
        },
        "id": "1KyTh6H5GbR4"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.595803Z",
          "iopub.status.busy": "2023-06-02T02:03:25.595524Z",
          "iopub.status.idle": "2023-06-02T02:03:25.604632Z",
          "shell.execute_reply": "2023-06-02T02:03:25.603918Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.595767Z"
        },
        "id": "N-mC3qyuBONc"
      },
      "outputs": [],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45AGAxHSnCXW"
      },
      "source": [
        "The classes are unbalanced, so it could be a good idea to oversample the training set such that all classes have the same count as the most populated one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geqa3e3zGUNL"
      },
      "source": [
        "# Oversampling del training set para reducir el desbalanceo de los datos de training\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.606268Z",
          "iopub.status.busy": "2023-06-02T02:03:25.605813Z",
          "iopub.status.idle": "2023-06-02T02:03:25.659048Z",
          "shell.execute_reply": "2023-06-02T02:03:25.658307Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.606225Z"
        },
        "id": "JN5OCli8BONe"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler()\n",
        "X_train, y_train = ros.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1));\n",
        "train_os = pd.DataFrame(list(zip([x[0] for x in X_train], y_train)), columns = ['text_clean', 'sentiment']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.660657Z",
          "iopub.status.busy": "2023-06-02T02:03:25.66031Z",
          "iopub.status.idle": "2023-06-02T02:03:25.665758Z",
          "shell.execute_reply": "2023-06-02T02:03:25.664901Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.660615Z"
        },
        "id": "qAwnlrGoBONe"
      },
      "outputs": [],
      "source": [
        "X_train = train_os['text_clean'].values\n",
        "y_train = train_os['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.667562Z",
          "iopub.status.busy": "2023-06-02T02:03:25.667173Z",
          "iopub.status.idle": "2023-06-02T02:03:25.6818Z",
          "shell.execute_reply": "2023-06-02T02:03:25.681064Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.667522Z"
        },
        "id": "zNopbN4gBONe"
      },
      "outputs": [],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-20xk2BE4Z4"
      },
      "source": [
        "# Naive Bayes baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Yapc55E4Z5"
      },
      "source": [
        "The first algorithm we will implement is Naive Bayes, which will be used as a simple baseline model. In order to use this algorithm, we need first need to preprocess the text data. <br>\n",
        "First, we will create a bag of words using CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:25.685312Z",
          "iopub.status.busy": "2023-06-02T02:03:25.685099Z",
          "iopub.status.idle": "2023-06-02T02:03:26.382481Z",
          "shell.execute_reply": "2023-06-02T02:03:26.381685Z",
          "shell.execute_reply.started": "2023-06-02T02:03:25.685285Z"
        },
        "id": "lRCIXRz5BONe"
      },
      "outputs": [],
      "source": [
        "clf = CountVectorizer()\n",
        "X_train_cv =  clf.fit_transform(X_train)\n",
        "X_test_cv = clf.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUKiklW7E4Z5"
      },
      "source": [
        "Then we apply TF-IFD transformation to associate weigths to the different words based on their frequency (rarer words will be given more importance)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:26.38421Z",
          "iopub.status.busy": "2023-06-02T02:03:26.383786Z",
          "iopub.status.idle": "2023-06-02T02:03:26.424232Z",
          "shell.execute_reply": "2023-06-02T02:03:26.4235Z",
          "shell.execute_reply.started": "2023-06-02T02:03:26.384165Z"
        },
        "id": "B_FoQa2cBONf"
      },
      "outputs": [],
      "source": [
        "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
        "X_train_tf = tf_transformer.transform(X_train_cv)\n",
        "X_test_tf = tf_transformer.transform(X_test_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrFr7QqHE4Z5"
      },
      "source": [
        "Finally we can instantiate the Naive Bayes model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkmWXbpJrW0z"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Crear y entrenar el modelo\n",
        "nb_clf = MultinomialNB(alpha=1.0)\n",
        "\n",
        "with mlflow.start_run():\n",
        "    # üîπ Loggear hiperpar√°metros\n",
        "    mlflow.log_param(\"alpha\", nb_clf.alpha)\n",
        "\n",
        "    # Entrenamiento\n",
        "    nb_clf.fit(X_train_tf, y_train)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = nb_clf.predict(X_test_tf)\n",
        "\n",
        "    # M√©tricas\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "    # üîπ Loggear m√©tricas\n",
        "    mlflow.log_metric(\"accuracy\", acc)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # üîπ Guardar modelo en MLflow\n",
        "    mlflow.sklearn.log_model(nb_clf, \"naive_bayes_model\")\n",
        "\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:26.460935Z",
          "iopub.status.busy": "2023-06-02T02:03:26.460619Z",
          "iopub.status.idle": "2023-06-02T02:03:26.467279Z",
          "shell.execute_reply": "2023-06-02T02:03:26.466491Z",
          "shell.execute_reply.started": "2023-06-02T02:03:26.460896Z"
        },
        "id": "Evr5z6nhBONf"
      },
      "outputs": [],
      "source": [
        "nb_pred = nb_clf.predict(X_test_tf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:26.469226Z",
          "iopub.status.busy": "2023-06-02T02:03:26.468949Z",
          "iopub.status.idle": "2023-06-02T02:03:26.4909Z",
          "shell.execute_reply": "2023-06-02T02:03:26.490022Z",
          "shell.execute_reply.started": "2023-06-02T02:03:26.469186Z"
        },
        "id": "4pUzmmo6BONf"
      },
      "outputs": [],
      "source": [
        "print('Classification Report for Naive Bayes:\\n',classification_report(y_test, nb_pred, target_names=sentiments))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-02T02:03:26.492722Z",
          "iopub.status.busy": "2023-06-02T02:03:26.492423Z",
          "iopub.status.idle": "2023-06-02T02:03:26.843489Z",
          "shell.execute_reply": "2023-06-02T02:03:26.842752Z",
          "shell.execute_reply.started": "2023-06-02T02:03:26.492663Z"
        },
        "id": "HygtpeD2E4Z6"
      },
      "outputs": [],
      "source": [
        "conf_matrix(y_test,nb_pred,'Naive Bayes Sentiment Analysis\\nConfusion Matrix', sentiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d4T9sivE4Z6"
      },
      "source": [
        "**The performance scores of the algorithm is very good, with an overall accurcy of 85%.<br>\n",
        "We can observe how the predictions for the more populated classes have very high F1 scores (over 85%), while for the class \"non-cyberbullying\" the score is much lower (61%).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4_8ThkbE4Z6"
      },
      "source": [
        "*Next we will implement a more complex algorithm to perform the classification, aiming to achieve higher accurcy than the baseline Naive Bayes model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMlmSzAFE4aF"
      },
      "source": [
        "# 2. BERT Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Ltzf_EE4aF"
      },
      "source": [
        "In this section, we will load a pre trained BERT model from the Hugging Face library and fine tune it for our classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXdeTLFFE4aF"
      },
      "source": [
        "First, we need to split the dataset into train - validation - test again since we need to tokenize the sentences differently from before (Naive Bayes and LSTM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6SU4CKxE4aF"
      },
      "source": [
        "## Train - Validation - Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:09.438232Z",
          "iopub.status.busy": "2023-06-02T02:04:09.437588Z",
          "iopub.status.idle": "2023-06-02T02:04:09.442761Z",
          "shell.execute_reply": "2023-06-02T02:04:09.441866Z",
          "shell.execute_reply.started": "2023-06-02T02:04:09.438188Z"
        },
        "id": "2l8aKG9xE4aF"
      },
      "outputs": [],
      "source": [
        "X = df['text_clean'].values\n",
        "y = df['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:09.444736Z",
          "iopub.status.busy": "2023-06-02T02:04:09.444438Z",
          "iopub.status.idle": "2023-06-02T02:04:09.475888Z",
          "shell.execute_reply": "2023-06-02T02:04:09.475228Z",
          "shell.execute_reply.started": "2023-06-02T02:04:09.444697Z"
        },
        "id": "Ml98xr0nE4aF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:09.477154Z",
          "iopub.status.busy": "2023-06-02T02:04:09.476916Z",
          "iopub.status.idle": "2023-06-02T02:04:09.504359Z",
          "shell.execute_reply": "2023-06-02T02:04:09.50357Z",
          "shell.execute_reply.started": "2023-06-02T02:04:09.477117Z"
        },
        "id": "AQHklFbSE4aF"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_tuo8ZbE4aF"
      },
      "source": [
        "As seen before, we oversample the text to the majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:09.505965Z",
          "iopub.status.busy": "2023-06-02T02:04:09.505518Z",
          "iopub.status.idle": "2023-06-02T02:04:09.522121Z",
          "shell.execute_reply": "2023-06-02T02:04:09.521446Z",
          "shell.execute_reply.started": "2023-06-02T02:04:09.505926Z"
        },
        "id": "ngR9fPXwE4aG"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler()\n",
        "X_train_os, y_train_os = ros.fit_resample(np.array(X_train).reshape(-1,1),np.array(y_train).reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:09.523414Z",
          "iopub.status.busy": "2023-06-02T02:04:09.523151Z",
          "iopub.status.idle": "2023-06-02T02:04:09.527605Z",
          "shell.execute_reply": "2023-06-02T02:04:09.526921Z",
          "shell.execute_reply.started": "2023-06-02T02:04:09.523376Z"
        },
        "id": "HuomVIfvE4aG"
      },
      "outputs": [],
      "source": [
        "X_train_os = X_train_os.flatten()\n",
        "y_train_os = y_train_os.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:09.529647Z",
          "iopub.status.busy": "2023-06-02T02:04:09.528781Z",
          "iopub.status.idle": "2023-06-02T02:04:09.540434Z",
          "shell.execute_reply": "2023-06-02T02:04:09.539499Z",
          "shell.execute_reply.started": "2023-06-02T02:04:09.529606Z"
        },
        "id": "V5zFw3GUE4aG"
      },
      "outputs": [],
      "source": [
        "(unique, counts) = np.unique(y_train_os, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJxUkOtpE4aG"
      },
      "source": [
        "# BERT Tokenizaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN4XSEA8E4aG"
      },
      "source": [
        "Since we need to tokenize the tweets (get \"input ids\" and \"attention masks\") for BERT, we load the specific BERT tokenizer from the Hugging Face library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:09.542271Z",
          "iopub.status.busy": "2023-06-02T02:04:09.541864Z",
          "iopub.status.idle": "2023-06-02T02:04:11.285025Z",
          "shell.execute_reply": "2023-06-02T02:04:11.284253Z",
          "shell.execute_reply.started": "2023-06-02T02:04:09.542234Z"
        },
        "id": "8uA0RyjVE4aG"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-15T08:35:46.046364Z",
          "iopub.status.busy": "2022-03-15T08:35:46.04601Z",
          "iopub.status.idle": "2022-03-15T08:35:46.076692Z",
          "shell.execute_reply": "2022-03-15T08:35:46.075417Z",
          "shell.execute_reply.started": "2022-03-15T08:35:46.046277Z"
        },
        "id": "v33texruE4aG"
      },
      "source": [
        "Then we define a custom tokenizer function using the loaded tokenizer.\n",
        "Se a√±ade el token spcial [CLS] para despu√©s poder clasificar el tipo de Tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:11.28677Z",
          "iopub.status.busy": "2023-06-02T02:04:11.286483Z",
          "iopub.status.idle": "2023-06-02T02:04:11.294126Z",
          "shell.execute_reply": "2023-06-02T02:04:11.293214Z",
          "shell.execute_reply.started": "2023-06-02T02:04:11.28673Z"
        },
        "id": "JeX_8folE4aH"
      },
      "outputs": [],
      "source": [
        "def bert_tokenizer(data):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for sent in data:\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sent,\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
        "            max_length=MAX_LEN,             # Choose max length to truncate/pad\n",
        "            padding='max_length',         # Pad sentence to max length\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa02_jTVE4aH"
      },
      "source": [
        "Since we need to specify the length of the longest tokenized sentence, we tokenize the train tweets using the \"encode\" method of the original BERT tokenizer and check the longest sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:11.296203Z",
          "iopub.status.busy": "2023-06-02T02:04:11.295883Z",
          "iopub.status.idle": "2023-06-02T02:04:29.249206Z",
          "shell.execute_reply": "2023-06-02T02:04:29.247551Z",
          "shell.execute_reply.started": "2023-06-02T02:04:11.296165Z"
        },
        "id": "jp8tRofWE4aH"
      },
      "outputs": [],
      "source": [
        "# Tokenize train tweets\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in X_train]\n",
        "\n",
        "# Find the longest tokenized tweet\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFskhQmWE4aH"
      },
      "source": [
        "We can choose the max length as 128."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:29.251156Z",
          "iopub.status.busy": "2023-06-02T02:04:29.250706Z",
          "iopub.status.idle": "2023-06-02T02:04:29.254856Z",
          "shell.execute_reply": "2023-06-02T02:04:29.254078Z",
          "shell.execute_reply.started": "2023-06-02T02:04:29.251113Z"
        },
        "id": "yukHwPSgE4aH"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htAnbpZNE4aH"
      },
      "source": [
        "Then we can tokenize the train, validation and test tweets using the custom define tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-06-02T02:04:29.256909Z",
          "iopub.status.busy": "2023-06-02T02:04:29.256411Z",
          "iopub.status.idle": "2023-06-02T02:05:01.094688Z",
          "shell.execute_reply": "2023-06-02T02:05:01.093823Z",
          "shell.execute_reply.started": "2023-06-02T02:04:29.256869Z"
        },
        "id": "Vule9amqE4aI"
      },
      "outputs": [],
      "source": [
        "train_inputs, train_masks = bert_tokenizer(X_train_os)\n",
        "val_inputs, val_masks = bert_tokenizer(X_valid)\n",
        "test_inputs, test_masks = bert_tokenizer(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlOj9i_0E4aI"
      },
      "source": [
        "## Data preprocessing for PyTorch BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPUGWFOBE4aI"
      },
      "source": [
        "Since we are using the BERT model built on PyTorch, we need to convert the arrays to pytorch tensors and create dataloaders for the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:01.096439Z",
          "iopub.status.busy": "2023-06-02T02:05:01.096172Z",
          "iopub.status.idle": "2023-06-02T02:05:01.100535Z",
          "shell.execute_reply": "2023-06-02T02:05:01.099735Z",
          "shell.execute_reply.started": "2023-06-02T02:05:01.0964Z"
        },
        "id": "IVuqOs1WE4aI"
      },
      "outputs": [],
      "source": [
        "# Convert target columns to pytorch tensors format\n",
        "train_labels = torch.from_numpy(y_train_os)\n",
        "val_labels = torch.from_numpy(y_valid)\n",
        "test_labels = torch.from_numpy(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s5b2vJnE4aI"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-7dsPFhE4aI"
      },
      "source": [
        "To fine-tune the BERT model, the original authors recommend a batch size of 16 or 32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:01.102537Z",
          "iopub.status.busy": "2023-06-02T02:05:01.102262Z",
          "iopub.status.idle": "2023-06-02T02:05:01.114354Z",
          "shell.execute_reply": "2023-06-02T02:05:01.11365Z",
          "shell.execute_reply.started": "2023-06-02T02:05:01.102491Z"
        },
        "id": "2wDSlFi8E4aI"
      },
      "outputs": [],
      "source": [
        "batch_size = 32 ##32 en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:01.115907Z",
          "iopub.status.busy": "2023-06-02T02:05:01.115581Z",
          "iopub.status.idle": "2023-06-02T02:05:01.126224Z",
          "shell.execute_reply": "2023-06-02T02:05:01.125464Z",
          "shell.execute_reply.started": "2023-06-02T02:05:01.115865Z"
        },
        "id": "KPloH7P2E4aI"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDxoDM_kE4aJ"
      },
      "source": [
        "# BERT Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSVNzTDd6lwm"
      },
      "source": [
        "# Clasificador de Sentimientos con BERT y PyTorch usando el token `[CLS]`\n",
        "\n",
        "En este cap√≠tulo, implementamos una arquitectura de red neuronal en **PyTorch** para la **clasificaci√≥n de sentimientos de tweets** utilizando **BERT** como modelo base. Para ello, definimos una clase llamada `BERTSentimentClassifier`.\n",
        "\n",
        "A diferencia de otros enfoques como el modelo `LSTM_Sentiment_Classifier` con mecanismo de atenci√≥n, en el que se asignan pesos a diferentes partes de la secuencia de entrada, el modelo basado en BERT aprovecha directamente el token especial `[CLS]`. Este token es agregado al inicio de cada secuencia de entrada y se entrena espec√≠ficamente para capturar una **representaci√≥n global del significado de la frase completa**, lo que lo hace ideal para tareas de clasificaci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "## ¬øC√≥mo funciona BERT en este contexto?\n",
        "\n",
        "**BERT** (Bidirectional Encoder Representations from Transformers) procesa todo el texto simult√°neamente (de manera **bidireccional**), prestando atenci√≥n a cada palabra en relaci√≥n con todas las dem√°s. El token `[CLS]`, que siempre se encuentra al inicio de la secuencia, **aprende una representaci√≥n contextualizada de todo el texto**.\n",
        "\n",
        "En nuestra clase `BERTSentimentClassifier`, utilizamos la salida correspondiente al token `[CLS]` como un **vector de caracter√≠sticas resumido** del tweet. Este vector se pasa a trav√©s de una **capa completamente conectada** (*fully connected*) y una **funci√≥n de activaci√≥n** (`Softmax` o `LogSoftmax`) para producir las **probabilidades finales** asociadas a cada clase de sentimiento.\n",
        "\n",
        "---\n",
        "\n",
        "## Arquitectura del Modelo\n",
        "\n",
        "La clase `BERTSentimentClassifier` incluye los siguientes componentes:\n",
        "\n",
        "- **Modelo BERT preentrenado** (`bert-base-uncased`, por ejemplo), cargado desde la librer√≠a `transformers`.\n",
        "- **Capa Dropout**, para prevenir *overfitting*.\n",
        "- **Capa lineal de clasificaci√≥n**, que toma la salida del token `[CLS]` y produce los *logits* para cada clase.\n",
        "- **Funci√≥n de activaci√≥n final**, como `LogSoftmax` o `Softmax`, seg√∫n la funci√≥n de p√©rdida utilizada.\n",
        "\n",
        "---\n",
        "\n",
        "## M√©todo `forward`\n",
        "\n",
        "En el m√©todo `forward`, se realiza lo siguiente:\n",
        "\n",
        "1. El texto de entrada se **tokeniza** y se convierte a tensores de `input_ids` y `attention_mask`.\n",
        "2. Estos tensores se **pasan al modelo BERT**.\n",
        "3. Se **extrae la salida del token `[CLS]`**, que se encuentra en la primera posici√≥n de la salida:  \n",
        "   `last_hidden_state[:, 0, :]`\n",
        "4. Esta representaci√≥n del `[CLS]` se pasa por la **capa dropout**, luego por la **capa lineal** y finalmente por la **funci√≥n de activaci√≥n**.\n",
        "5. Se devuelve la **distribuci√≥n de probabilidad sobre las clases de salida**.\n",
        "\n",
        "---\n",
        "\n",
        "## Ventajas del uso de BERT con el token `[CLS]`\n",
        "\n",
        "Usar BERT con el token `[CLS]` permite **capturar autom√°ticamente relaciones complejas** dentro del texto sin necesidad de implementar manualmente mecanismos de atenci√≥n como en los modelos LSTM.  \n",
        "\n",
        "BERT ha sido preentrenado con grandes vol√∫menes de texto, por lo que su capacidad para **entender el contexto** es significativamente superior.\n",
        "\n",
        "Esto lo hace particularmente adecuado para tareas como el **an√°lisis de sentimientos**, donde el contexto y la ambig√ºedad del lenguaje juegan un papel cr√≠tico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wWGQ1iSE4aJ"
      },
      "source": [
        "Now we can create a custom BERT classifier class, including the original BERT model (made of transformer layers) and additional Dense layers to perform the desired classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:01.127961Z",
          "iopub.status.busy": "2023-06-02T02:05:01.127533Z",
          "iopub.status.idle": "2023-06-02T02:05:01.139718Z",
          "shell.execute_reply": "2023-06-02T02:05:01.138831Z",
          "shell.execute_reply.started": "2023-06-02T02:05:01.127919Z"
        },
        "id": "aDOjw7OlE4aJ"
      },
      "outputs": [],
      "source": [
        "class Bert_Classifier(nn.Module):\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        super(Bert_Classifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of the classifier, and number of labels\n",
        "        n_input = 768\n",
        "        n_hidden = 50\n",
        "        n_output = 5\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate the classifier (a fully connected layer followed by a ReLU activation and another fully connected layer)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(n_input, n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden, n_output)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model weights if freeze_bert is True (useful for feature extraction without fine-tuning)\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Feed input data (input_ids and attention_mask) to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the `[CLS]` token from the BERT output (useful for classification tasks)\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :] # este token es el que va avaler para clasificar\n",
        "\n",
        "        # Feed the extracted hidden state to the classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv6uzl8EE4aJ"
      },
      "source": [
        "Moreover, since we want to define a learning rate scheduler, we define a custom \"initalize_model\" function as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:01.141755Z",
          "iopub.status.busy": "2023-06-02T02:05:01.140963Z",
          "iopub.status.idle": "2023-06-02T02:05:01.153984Z",
          "shell.execute_reply": "2023-06-02T02:05:01.153141Z",
          "shell.execute_reply.started": "2023-06-02T02:05:01.141715Z"
        },
        "id": "JFeSRDIqE4aK"
      },
      "outputs": [],
      "source": [
        "# Function for initializing the BERT Classifier model, optimizer, and learning rate scheduler\n",
        "def initialize_model(epochs=4):\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = Bert_Classifier(freeze_bert=False)\n",
        "\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # learning rate, set to default value\n",
        "                      eps=1e-8    # decay, set to default value\n",
        "                      )\n",
        "\n",
        "    # Calculate total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Define the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ-mNpTfE4aK"
      },
      "source": [
        "We also specify the use of GPU if present (highly recommended for the fine tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:01.156025Z",
          "iopub.status.busy": "2023-06-02T02:05:01.155042Z",
          "iopub.status.idle": "2023-06-02T02:05:01.166688Z",
          "shell.execute_reply": "2023-06-02T02:05:01.165952Z",
          "shell.execute_reply.started": "2023-06-02T02:05:01.155979Z"
        },
        "id": "jzKFFd2kE4aK"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EPOCHS=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXL_iJfDE4aK"
      },
      "source": [
        "And then we intialize the BERT model calling the \"initialize_model\" function we defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:01.168188Z",
          "iopub.status.busy": "2023-06-02T02:05:01.167823Z",
          "iopub.status.idle": "2023-06-02T02:05:03.081637Z",
          "shell.execute_reply": "2023-06-02T02:05:03.080731Z",
          "shell.execute_reply.started": "2023-06-02T02:05:01.168146Z"
        },
        "id": "RoimyTJTE4aK"
      },
      "outputs": [],
      "source": [
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcdlgqWzE4aK"
      },
      "source": [
        "# BERT Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0oi_jJSE4aL"
      },
      "source": [
        "After defining the custom BERT classifier model, we are ready to start the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:03.0835Z",
          "iopub.status.busy": "2023-06-02T02:05:03.08323Z",
          "iopub.status.idle": "2023-06-02T02:05:03.102832Z",
          "shell.execute_reply": "2023-06-02T02:05:03.102029Z",
          "shell.execute_reply.started": "2023-06-02T02:05:03.08346Z"
        },
        "id": "Q25C2I7qE4aL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch  # Para guardar modelos PyTorch en MLflow\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch  # Para guardar modelos PyTorch en MLflow\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "\n",
        "# Define Cross entropy Loss function for the multiclass classification task\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def bert_train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False,\n",
        "               learning_rate=2e-5, batch_size=32, optimizer_name=\"AdamW\"):\n",
        "\n",
        "    # Optimizer y scheduler (los declaramos aqu√≠ dentro)\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    # Inicia el experimento de MLflow\n",
        "    with mlflow.start_run():\n",
        "\n",
        "        # üîπ Registrar hiperpar√°metros\n",
        "        mlflow.log_param(\"epochs\", epochs)\n",
        "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"optimizer\", optimizer_name)\n",
        "\n",
        "        print(\"Start training...\\n\")\n",
        "        for epoch_i in range(epochs):\n",
        "            print(\"-\"*10)\n",
        "            print(\"Epoch : {}\".format(epoch_i+1))\n",
        "            print(\"-\"*10)\n",
        "            print(\"-\"*38)\n",
        "            print(f\"{'BATCH NO.':^7} | {'TRAIN LOSS':^12} | {'ELAPSED (s)':^9}\")\n",
        "            print(\"-\"*38)\n",
        "\n",
        "            # Measure the elapsed time of each epoch\n",
        "            t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "            total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "            ### TRAINING ###\n",
        "            model.train()\n",
        "\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_counts += 1\n",
        "                b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "                model.zero_grad()\n",
        "                logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "                loss = loss_fn(logits, b_labels)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                if (step % 100 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                    time_elapsed = time.time() - t0_batch\n",
        "                    print(f\"{step:^9} | {batch_loss / batch_counts:^12.6f} | {time_elapsed:^9.2f}\")\n",
        "                    batch_loss, batch_counts = 0, 0\n",
        "                    t0_batch = time.time()\n",
        "\n",
        "            avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "            ### EVALUATION ###\n",
        "            model.eval()\n",
        "            val_accuracy, val_loss = [], []\n",
        "\n",
        "            for batch in val_dataloader:\n",
        "                batch_input_ids, batch_attention_mask, batch_labels = tuple(t.to(device) for t in batch)\n",
        "                with torch.no_grad():\n",
        "                    logits = model(batch_input_ids, batch_attention_mask)\n",
        "\n",
        "                loss = loss_fn(logits, batch_labels)\n",
        "                val_loss.append(loss.item())\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1).flatten()\n",
        "                accuracy = (preds == batch_labels).cpu().numpy().mean() * 100\n",
        "                val_accuracy.append(accuracy)\n",
        "\n",
        "            val_loss = np.mean(val_loss)\n",
        "            val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            print(\"-\"*61)\n",
        "            print(f\"{'AVG TRAIN LOSS':^12} | {'VAL LOSS':^10} | {'VAL ACCURACY (%)':^9} | {'ELAPSED (s)':^9}\")\n",
        "            print(\"-\"*61)\n",
        "            print(f\"{avg_train_loss:^14.6f} | {val_loss:^10.6f} | {val_accuracy:^17.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*61)\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # üîπ Loggear m√©tricas en MLflow\n",
        "            mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch_i)\n",
        "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch_i)\n",
        "            mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch_i)\n",
        "\n",
        "        # üîπ Guardar el modelo al final del entrenamiento\n",
        "        mlflow.pytorch.log_model(model, \"bert_model\")\n",
        "\n",
        "        print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:05:03.105292Z",
          "iopub.status.busy": "2023-06-02T02:05:03.104233Z",
          "iopub.status.idle": "2023-06-02T02:15:53.834438Z",
          "shell.execute_reply": "2023-06-02T02:15:53.833452Z",
          "shell.execute_reply.started": "2023-06-02T02:05:03.105259Z"
        },
        "id": "hLe9Cxa5E4aL",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "bert_train(bert_classifier, train_dataloader, val_dataloader, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB6mbcKSE4aM"
      },
      "source": [
        "# BERT Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm7vdZpGE4aM"
      },
      "source": [
        "Now we define a function similar to the model \"evaluation\", where we feed to the model the test data instead of the validation data."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oJQvNouhBah0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:15:53.836407Z",
          "iopub.status.busy": "2023-06-02T02:15:53.836041Z",
          "iopub.status.idle": "2023-06-02T02:15:53.844432Z",
          "shell.execute_reply": "2023-06-02T02:15:53.843261Z",
          "shell.execute_reply.started": "2023-06-02T02:15:53.836365Z"
        },
        "id": "k9X4pTy5E4aM"
      },
      "outputs": [],
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "\n",
        "    # Define empty list to host the predictions\n",
        "    preds_list = []\n",
        "\n",
        "    # Put the model into evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        batch_input_ids, batch_attention_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Avoid gradient calculation of tensors by using \"no_grad()\" method\n",
        "        with torch.no_grad():\n",
        "            logit = model(batch_input_ids, batch_attention_mask)\n",
        "\n",
        "        # Get index of highest logit\n",
        "        pred = torch.argmax(logit,dim=1).cpu().numpy()\n",
        "        # Append predicted class to list\n",
        "        preds_list.extend(pred)\n",
        "\n",
        "    return preds_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sGz67XnE4aM"
      },
      "source": [
        "Then we can call the defined function and get the class predictions of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:15:53.846259Z",
          "iopub.status.busy": "2023-06-02T02:15:53.845986Z",
          "iopub.status.idle": "2023-06-02T02:16:21.645265Z",
          "shell.execute_reply": "2023-06-02T02:16:21.644443Z",
          "shell.execute_reply.started": "2023-06-02T02:15:53.846222Z"
        },
        "id": "ESoBNY1VE4aM"
      },
      "outputs": [],
      "source": [
        "bert_preds = bert_predict(bert_classifier, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:16:21.647186Z",
          "iopub.status.busy": "2023-06-02T02:16:21.646916Z",
          "iopub.status.idle": "2023-06-02T02:16:21.670352Z",
          "shell.execute_reply": "2023-06-02T02:16:21.669487Z",
          "shell.execute_reply.started": "2023-06-02T02:16:21.647147Z"
        },
        "id": "WC7ZzHPNE4aM"
      },
      "outputs": [],
      "source": [
        "print('Classification Report for BERT :\\n', classification_report(y_test, bert_preds, target_names=sentiments))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-02T02:16:21.672093Z",
          "iopub.status.busy": "2023-06-02T02:16:21.671819Z",
          "iopub.status.idle": "2023-06-02T02:16:22.103134Z",
          "shell.execute_reply": "2023-06-02T02:16:22.102395Z",
          "shell.execute_reply.started": "2023-06-02T02:16:21.672055Z"
        },
        "id": "y8Mr4toqE4aN"
      },
      "outputs": [],
      "source": [
        "conf_matrix(y_test, bert_preds,' BERT Sentiment Analysis\\nConfusion Matrix', sentiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nCg9yljE4aN"
      },
      "source": [
        "**El rendimiento del clasificador BERT es bastante alto y superior al obtenido usando el modelo base Naive Bayes, con una precisi√≥n global de aproximadamente 94% y puntuaciones F1 por encima del 94%.**<br>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 1869236,
          "sourceId": 3053020,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30154,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}